{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd17780a-e93c-4686-a1a7-d3035606a452",
   "metadata": {},
   "source": [
    "## This notebook preprocesses the ISIC 2019 dataset for skin lesion classification. The steps include:\n",
    "- Loading and cleaning the dataset\n",
    "- Splitting data into train, validation, and test sets\n",
    "- Computing class weights to handle imbalanced classes\n",
    "- Setting up data augmentation for training\n",
    "- Saving processed data for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b84db17-5d2c-4a40-af5d-56e0140e6ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 18:11:43.112560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-22 18:11:43.963746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f11878-f420-4126-a8fa-6757411b4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to dataset\n",
    "data_path = '../data/ISIC_2019_Training_Input' # Directory containing images\n",
    "csv_path = '../data/ISIC_2019_Training_GroundTruth.csv'  # Ground truth CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653413fd-ca1e-4644-890d-4dcdaec49bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(csv_path), f\"File {csv_path} not found!\"\n",
    "assert os.path.exists(data_path), f\"File {data_path} not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3b5886-a103-4e0b-8c21-9e9f577b4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Cleaning data...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and clean the dataset\n",
    "print('Loading and Cleaning data...')\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce65b05-d29a-47f2-b15f-b43076db1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with invalid labels (ensure exactly one label per row)\n",
    "df = df[df[['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']].sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f88da5e-64e6-4a74-b6a6-c1ddd34b8241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of deleted rows: 0\n"
     ]
    }
   ],
   "source": [
    "invalid_rows = len(pd.read_csv(csv_path)) - len(df)\n",
    "print(f\"Count of deleted rows: {invalid_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883a23d9-8bdf-40cb-99eb-ce0acf24b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image paths to DataFrame for easy access\n",
    "df['image_path'] = df['image'].apply(lambda x: os.path.join(data_path, x + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c84964-1b4c-4c0e-b9b8-868c2fc1d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AK</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "      <th>SCC</th>\n",
       "      <th>UNK</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../data/ISIC_2019_Training_Input/ISIC_0000000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../data/ISIC_2019_Training_Input/ISIC_0000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../data/ISIC_2019_Training_Input/ISIC_0000002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../data/ISIC_2019_Training_Input/ISIC_0000003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../data/ISIC_2019_Training_Input/ISIC_0000004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK  \\\n",
       "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "\n",
       "                                          image_path  \n",
       "0  ../data/ISIC_2019_Training_Input/ISIC_0000000.jpg  \n",
       "1  ../data/ISIC_2019_Training_Input/ISIC_0000001.jpg  \n",
       "2  ../data/ISIC_2019_Training_Input/ISIC_0000002.jpg  \n",
       "3  ../data/ISIC_2019_Training_Input/ISIC_0000003.jpg  \n",
       "4  ../data/ISIC_2019_Training_Input/ISIC_0000004.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88971d3f-3492-4e3a-b107-31a66d096635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 25331\n"
     ]
    }
   ],
   "source": [
    "# Check for invalid or missing images\n",
    "def check_image(img_path):\n",
    "    \"\"\"Check if an image file exists and can be read.\"\"\"\n",
    "    if not os.path.exists(img_path):\n",
    "        return False\n",
    "    img = cv.imread(img_path)\n",
    "    return img is not None\n",
    "\n",
    "df['valid_image'] = df['image_path'].apply(check_image)\n",
    "# df = df[df['valid_image']].drop(columns = ['valid_image'])\n",
    "print(f\"Total valid images: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2241de37-df47-4542-be85-4b84d3658892",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_images = df[~df['valid_image']]['image'].tolist()\n",
    "if invalid_images:\n",
    "    print(f\"invalid_images: {invalid_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93941eb-95a5-43e6-b6dc-2a5630a8f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['valid_image']].drop(columns = ['valid_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a721e7-5d0b-4720-8bce-3400d1ce99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert one-hot encoded labels to categorical\n",
    "class_columns = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n",
    "df['label'] = df[class_columns].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc78ea9-5a8a-4e08-90ab-d501a8bd76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Train: 17731, Validation: 3800, Test: 3800\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Split data into train (70%), validation (15%) and test (15%) sets\n",
    "print('Splitting data...')\n",
    "train_df, temp_df = train_test_split(df, test_size = 0.3, stratify = df['label'], random_state = 42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size = 0.5, stratify = temp_df['label'], random_state = 42)\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca126cd-34ef-473c-a722-75e866fd12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution Train:\n",
      "label\n",
      "NV      9012\n",
      "MEL     3165\n",
      "BCC     2326\n",
      "BKL     1837\n",
      "AK       607\n",
      "SCC      440\n",
      "VASC     177\n",
      "DF       167\n",
      "Name: count, dtype: int64\n",
      "Class distribution Validation:\n",
      "label\n",
      "NV      1932\n",
      "MEL      678\n",
      "BCC      498\n",
      "BKL      394\n",
      "AK       130\n",
      "SCC       94\n",
      "VASC      38\n",
      "DF        36\n",
      "Name: count, dtype: int64\n",
      "Class distribution Test:\n",
      "label\n",
      "NV      1931\n",
      "MEL      679\n",
      "BCC      499\n",
      "BKL      393\n",
      "AK       130\n",
      "SCC       94\n",
      "VASC      38\n",
      "DF        36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution Train:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"Class distribution Validation:\")\n",
    "print(val_df['label'].value_counts())\n",
    "print(\"Class distribution Test:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563a8eb2-1a2f-4f8b-9256-56d97d9f7aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "['AK' 'BCC' 'BKL' 'DF' 'MEL' 'NV' 'SCC' 'VASC']\n",
      "Class weights: {'AK': 3.652104959630911, 'BCC': 0.9528663857959675, 'BKL': 1.2066977896341464, 'DF': 13.248430962343097, 'MEL': 0.7002156125608138, 'NV': 0.24593203883495146, 'SCC': 5.041998407643312, 'VASC': 12.515316205533598}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Compute class weights to handle imbalanced classes\n",
    "print(\"Computing class weights...\")\n",
    "classes = np.unique(df['label'])\n",
    "print(classes)\n",
    "class_weights = compute_class_weight('balanced', classes = classes, y = df['label'])\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc5779cf-9a64-4549-bab5-0f0e2120ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17731 validated image filenames belonging to 8 classes.\n",
      "Found 3800 validated image filenames belonging to 8 classes.\n",
      "Found 3800 validated image filenames belonging to 8 classes.\n",
      "Class indices: {'AK': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'SCC': 6, 'VASC': 7}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Set up data augmentation for training and normalization for validation/test\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,    rotation_range = 20, # Random rotation up to 20 degrees\n",
    "    width_shift_range = 0.2, # Random horizontal shift\n",
    "    height_shift_range = 0.2, # Random vertical shift\n",
    "    horizontal_flip = True, # Random horizontal flip\n",
    "    zoom_range = 0.2, # Random zoom\n",
    "    fill_mode = 'nearest' # Fill new pixels with nearest value\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input) # Only normalize for validation/test\n",
    "\n",
    "# Configure data generators\n",
    "target_size = (224, 224) # Resize images for EfficientNetB0\n",
    "batch_size = 16 \n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False # Keep test data order to evaluation   \n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03831695-ef19-4ac2-9930-9f439d3a5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save processed DataFrames for reproducibility\n",
    "train_df.to_csv('train_split.csv', index = False)\n",
    "val_df.to_csv('val_split.csv', index = False)\n",
    "test_df.to_csv('test_split.csv', index = False)\n",
    "print('Data splits saved as CSV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e0197f-b308-4127-a8f8-fd5c79a1e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save class weights for training\n",
    "np.save('class_weights.npy', class_weight_dict)\n",
    "print('Class weights saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1130ef4-6a5a-48a7-9e34-5a42f8a2f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('train_split.csv'), \"train_split.csv didn't save!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
